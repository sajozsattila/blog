{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7cb31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6276eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54c36f",
   "metadata": {},
   "source": [
    "# Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_redshift(connection_parameters: Dict, query: str):\n",
    "    import redshift_connector\n",
    "    import pandas as pd\n",
    "    df = None\n",
    "\n",
    "    logger.info(f'Running {query} on RedShift!')\n",
    "    logger.info(f'Redshift connection_parameters: {connection_parameters}')\n",
    "    try:\n",
    "        with redshift_connector.connect(\n",
    "                host=connection_parameters['host'],\n",
    "                database=connection_parameters['database'],\n",
    "                user=connection_parameters['user'],\n",
    "                password=connection_parameters['password'],\n",
    "                port=int(connection_parameters['port']),\n",
    "                ssl=False\n",
    "        ) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                df = pd.read_sql_query(query, conn)\n",
    "    except Exception as e:\n",
    "        logger.warning(f'Can not connect to Redshift: {e}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6522bcef",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577c417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = datasets.load_wine()\n",
    "df_mulitclass = pd.DataFrame(\n",
    "    data= np.c_[dataset['data'], dataset['target']],\n",
    "    columns= dataset['feature_names'] + ['target']\n",
    ")\n",
    "dataset = datasets.fetch_california_housing()\n",
    "df_regression = pd.DataFrame(\n",
    "    data= np.c_[dataset['data'], dataset['target']],\n",
    "    columns= dataset['feature_names'] + ['target']\n",
    ")\n",
    "dataset = datasets.load_breast_cancer()\n",
    "df_binary_class = pd.DataFrame(\n",
    "    data= np.c_[dataset['data'], dataset['target']],\n",
    "    columns= dataset['feature_names'].tolist() + ['target']\n",
    ")\n",
    "\n",
    "df = df_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557a08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_columns = list(df.drop(['target'], axis=1).columns)\n",
    "X = df[feature_columns]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42967955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14448, 8) (6192, 8) (14448,) (6192,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45003375",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca4823",
   "metadata": {},
   "source": [
    "## Profiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d2eeb",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson\n",
    "from scipy import stats\n",
    "stats.pearsonr(df['continous'], df['continous2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-Biserial \n",
    "#  continous vs. binary\n",
    "from scipy import stats\n",
    "stats.pointbiserialr(df['continous'], df['binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phi Coefficient\n",
    "#  binary vs binary\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(df['binary'], df['binary2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ca1f2",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2796ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour_sin'] = np.sin(2*np.pi/24*df['hour'])\n",
    "df['hour_cos'] = np.cos(2*np.pi/24*df['hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8239a9d",
   "metadata": {},
   "source": [
    "# Hyperparamter optimalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa071163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import Input\n",
    "from keras.optimizers import Adadelta, Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class Hyperparam_opt():\n",
    "    def __init__(self, buildmodel, space, score, loss=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          * buildmodel -- f(params, traning_X, traning_y), a function which is used for training a single model\n",
    "          * space -- the space for the hyperparamter optialization\n",
    "          * score -- how we score the model, need to sync with the 'loss'\n",
    "                     if hight score is the better model, we need to set the 'loss' to False\n",
    "          * loss -- the score is a loss function or not, it is loss if the smaller value is better,\n",
    "                    ex: f1 is not one, as 1 is the best and 0 is the worst value\n",
    "        \"\"\"\n",
    "        self.buildmodel = buildmodel\n",
    "        self.space = space\n",
    "        self.score = score\n",
    "        self.loss = loss\n",
    "        self.models = []\n",
    "    \n",
    "    def hyperparameter_tuning(self, space):\n",
    "        #\"\"\"\n",
    "        # Define the K-fold Cross Validator\n",
    "        kfold = KFold(n_splits=self.n_splits)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kfold.split(self.X_train, self.y_train):\n",
    "            model = self.buildmodel(space, self.X_train[train_idx], self.y_train[train_idx])\n",
    "            try:\n",
    "                pred_auc = model.predict(self.X_train[test_idx], verbose = 0)\n",
    "            except:\n",
    "                pred_auc = model.predict(self.X_train[test_idx])\n",
    "            scores.append( self.score(self.y_train[test_idx], pred_auc) )\n",
    "        self.models.append({})\n",
    "        self.models[-1]['space'] = space\n",
    "        self.models[-1]['scores'] = scores\n",
    "        self.models[-1]['loss'] =  np.mean(scores)\n",
    "        if not self.loss:\n",
    "            self.models[-1]['loss'] =  1-np.mean(scores)\n",
    "        return {'loss': self.models[-1]['loss'], 'status': STATUS_OK}\n",
    "    \n",
    "    def train(self, X_train, y_train, X_test, y_test, n_splits=5, max_eval=100):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        # split for K fold CV\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "        trials = Trials()\n",
    "        # best arguments\n",
    "        self.best_args = fmin(\n",
    "            fn=self.hyperparameter_tuning,\n",
    "            space=self.space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_eval,\n",
    "            trials=trials)\n",
    "        # the best model\n",
    "        self.model = self.buildmodel(self.best_args, X_train, y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9aaa78",
   "metadata": {},
   "source": [
    "## LightGBM binarry classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import lightgbm as ltb\n",
    "\n",
    "# hyperparamter space for lightgbm\n",
    "space_boost = {\n",
    "    'num_leaves': hp.quniform(\"num_leaves\", 4, 160, 2),\n",
    "    'min_child_samples': hp.quniform(\"min_child_samples\", 100, 3000, 100),\n",
    "}\n",
    "\n",
    "# one single LightGBM model fit\n",
    "def build_boost_model(params, traning_X, traning_y):\n",
    "    model = ltb.LGBMClassifier(\n",
    "            num_leaves=int(params['num_leaves']),\n",
    "            min_child_samples=int(params['min_child_samples']),\n",
    "            is_unbalance=True\n",
    "    )\n",
    "    # train model        \n",
    "    model.fit(traning_X, traning_y)\n",
    "    return model\n",
    "\n",
    "# hyperparamter optimalization\n",
    "boost_model = Hyperparam_opt(\n",
    "    build_boost_model,\n",
    "    space_boost, \n",
    "    f1_score, \n",
    "    loss=False\n",
    ")\n",
    "boost_model.train(X_train.values, y_train.values, X_test.values, y_test.values, max_eval=1)\n",
    "\n",
    "# predict with the optimalised model\n",
    "predicted_y = boost_model.model.predict(X_test)\n",
    "score = f1_score(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a7732",
   "metadata": {},
   "source": [
    "## LightGBPM multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import lightgbm as ltb\n",
    "\n",
    "# hyperparamter space for lightgbm\n",
    "space_boost = {\n",
    "    'num_leaves': hp.quniform(\"num_leaves\", 4, 160, 2),\n",
    "    'min_child_samples': hp.quniform(\"min_child_samples\", 100, 3000, 100),\n",
    "}\n",
    "\n",
    "# ROC is better when classes is balanced\n",
    "def roc_multiclass(y_test, y_pred):\n",
    "    return roc_auc_score(y_test, y_pred, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "# one single LightGBM model fit\n",
    "def build_boost_model(params, traning_X, traning_y):\n",
    "    model = ltb.LGBMClassifier(\n",
    "            num_leaves=int(params['num_leaves']),\n",
    "            min_child_samples=int(params['min_child_samples']),\n",
    "            is_unbalance=True\n",
    "    )\n",
    "    # overwrite predict fucntion with probability prediction as we use ROC for evaluation \n",
    "    model.predict = model.predict_proba\n",
    "    # train model        \n",
    "    model.fit(traning_X, traning_y)\n",
    "    return model\n",
    "\n",
    "# hyperparamter optimalization\n",
    "boost_model = Hyperparam_opt(\n",
    "    build_boost_model,\n",
    "    space_boost, \n",
    "    roc_multiclass, \n",
    "    loss=False\n",
    ")\n",
    "boost_model.train(X_train.values, y_train.values, X_test.values, y_test.values, max_eval=10)\n",
    "\n",
    "# predict with the optimalised model\n",
    "predicted_y = boost_model.model.predict(X_test.values)\n",
    "score = roc_multiclass(y_test, predicted_y)\n",
    "print(score)\n",
    "# turn to Probability to class label\n",
    "predicted_y = predicted_y.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a57220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import lightgbm as ltb\n",
    "\n",
    "# hyperparamter space for lightgbm\n",
    "space_boost = {\n",
    "    'num_leaves': hp.quniform(\"num_leaves\", 4, 160, 2),\n",
    "    'min_child_samples': hp.quniform(\"min_child_samples\", 100, 3000, 100),\n",
    "}\n",
    "\n",
    "# own f1 function for multiclass is good when there is class inblance\n",
    "def f1_multiclass(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# one single LightGBM model fit\n",
    "def build_boost_model(params, traning_X, traning_y):\n",
    "    model = ltb.LGBMClassifier(\n",
    "            num_leaves=int(params['num_leaves']),\n",
    "            min_child_samples=int(params['min_child_samples']),\n",
    "            is_unbalance=True\n",
    "    )\n",
    "    # train model        \n",
    "    model.fit(traning_X, traning_y)\n",
    "    return model\n",
    "\n",
    "# hyperparamter optimalization\n",
    "boost_model = Hyperparam_opt(\n",
    "    build_boost_model,\n",
    "    space_boost, \n",
    "    f1_multiclass, \n",
    "    loss=False\n",
    ")\n",
    "boost_model.train(X_train.values, y_train.values, X_test.values, y_test.values, max_eval=100)\n",
    "\n",
    "# predict with the optimalised model\n",
    "predicted_y = boost_model.model.predict(X_test.values)\n",
    "score = f1_multiclass(y_test, predicted_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78005",
   "metadata": {},
   "source": [
    "## LightGBM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0894326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81trial/s, best loss: 0.27576107166512165]\n",
      "0.24998006441316417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import lightgbm as ltb\n",
    "\n",
    "# hyperparamter space for lightgbm\n",
    "space_boost = {\n",
    "    'num_leaves': hp.quniform(\"num_leaves\", 4, 160, 2),\n",
    "    'min_child_samples': hp.quniform(\"min_child_samples\", 100, 3000, 100),\n",
    "}\n",
    "\n",
    "# one single LightGBM model fit\n",
    "def build_boost_model(params, traning_X, traning_y):\n",
    "    model = ltb.LGBMRegressor(\n",
    "            num_leaves=int(params['num_leaves']),\n",
    "            min_child_samples=int(params['min_child_samples']),\n",
    "    )\n",
    "    # train model        \n",
    "    model.fit(traning_X, traning_y)\n",
    "    return model\n",
    "\n",
    "# hyperparamter optimalization\n",
    "boost_model = Hyperparam_opt(\n",
    "    build_boost_model,\n",
    "    space_boost, \n",
    "    mean_absolute_percentage_error, \n",
    "    loss=True\n",
    ")\n",
    "boost_model.train(X_train.values, y_train.values, X_test.values, y_test.values, max_eval=1)\n",
    "\n",
    "# predict with the optimalised model\n",
    "predicted_y = boost_model.model.predict(X_test.values)\n",
    "score = mean_absolute_percentage_error(y_test, predicted_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f12f5",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1181f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dbece22",
   "metadata": {},
   "source": [
    "# Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix,  ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted_y, normalize='true')\n",
    "cm_no_norm = confusion_matrix(y_test, predicted_y)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "ConfusionMatrixDisplay(cm).plot(ax=ax1)\n",
    "ConfusionMatrixDisplay(cm_no_norm).plot(ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP value\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(boost_model.model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d96ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precission recall\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# from model\n",
    "pr_boost = PrecisionRecallDisplay.from_estimator(\n",
    "    boost_model.model, X_test, y_test, name=\"Boosting\"\n",
    ")\n",
    "# from prediction\n",
    "pr_nn = PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, pre_nn, name=\"NN\"\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "_ = pr_boost.plot(ax=ax1);\n",
    "_ = pr_nn.plot(ax=ax1);\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
